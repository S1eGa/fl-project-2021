# fl-project-2021 #

1. [Boost-spirit](#Boost-Spirit)
2. [Parsec](#Parsec)
3. [Pyparse](#Pyparse)

## Boost-Spirit

Используются зависимости:

* boost/spirit
* boost/fusion
* boost/variant

Компиляция проекта происходит при помощи ввода следующей команды:

``` bash
   g++ main.cpp -o src 
```

При запуске программа ожидает путь до файла, написанному на языке
из [description.txt](/description.txt). На выход выдается построенное
AST в случае, если программа принадлежит данному языку
или сообщение об ошибке в обратном случае.

Из особенностей

* Свой лексер и интеграция с ним (так и не воспользовался)
* Интеграция с библиотекой boost::fusion, позволяющая делать различные
  функциональные штуки
* Очень удобная перегрузка операторов для правил

## Тестирование ##

Первые 11 тестов должны показывать, что парсер распознает
языковые особенности, последние два - стрессы. На тесты большего
порядка просто не хватает стека, но и с такими время выполнения
уже достаточно большое. В частности,

```bash
Test #13
real    0m2,653s
user    0m2,442s
sys     0m0,052s
```

```bash
Test #14
real    0m0,618s
user    0m0,601s
sys     0m0,016s
```

Разница в размере входных данных примерно в два раза, но время
отличается так из-за количества откатов. Так как парсер
внутри Boost::Spirit использует алгоритм нисходящего рекурсивного
спуска, то в худшем случае может потребоваться экспоненциальное время.
Так же серьезным фактором, влияющем на время, является объем выходных
данных. Для теста `#13`  он составляет 42 мегабайта, что уже может
в значительной мере повлиять на время выполнения.

При ошибке парсер возвращает фрагмент входного файла, начиная
с первой не распознанной функции.

## Parsec, Haskell ##

1. Библиотекa монадических парсер комбинаторов `parsec`, библиотека с хорошей документацией,
   большим количеством примеров.
2. Библиотека достаточно удобная, например есть встроенный парсер `buildExpressionParser`,
   который сильно облегчает парсинг языка, синтаксис очень интуитивный.
3. Обработка ошибок. Встроенная обработка ошибок в `parsec` уже имеет хорошую форму. Сообщение выглядит так:
   строка, символ, какой символ ожидался на самом деле. Пользователю эта информация может быть достаточно полезна, для того чтобы понять, как исправить код. С возможностью кастомизировать сообщения об ошибках я не разбирался.
4. Сложности и минусы `parsec`. Внутри `parsec` работает как LL(1) парсер, что конечно неплохо, но слабее, чем   парсеры из бизона или других парсер-генераторов. Из-за этого, например, в случае `statement = expression`
   `expression` не может начинаться с маленькой латинской буквы, так как там возникает неоднозначность - либо ожидается `assignment` либо `expression`. В таком случае нужно обернуть `expression` в скобки, чтобы все разбиралось однозначно. Помимо этого в остальных местах где были неоднозначности надо было аккуратно задать грамматику.
5. Время работы на тесте 4 -- 0.9s (724836 байт), на тесте 5 -- 5.8s (2524836 байт), на тесте 6 -- 0.18s (70037 байт). Большие тесты состоят в основном только из выражений, так как вся сложность парсинга приходится именно на выажения, так как все `statement` имеют достаточно простую структуру. Для того чтобы запустить тесты достаточно запустить функцию `checkFile path/to/test`.

## Pyparsing, Python

### Сборка
   1. `pip3 install pyparsing`
   2. `python3 parser.py`

### Информация о парсер-комбинаторе `pyparsec`
   1. Это парсер-комбинатор, который основан на `PEG`, а не `CFG`. Преимущество заключается в том, что `PEG` лучше умеет обрабатвать `choice operator` (то есть, по сути, некоторые неоднозначности грамматики)

   2. Плюсы библиотеки:
      - Достаточно сильно можно кастомизировать процесс парсинга, передавать свои обработчики токенов, заматченных отдельными правилами
      - Наличие неплохой документации и примеров, по которым можно разбираться с библиотекой
      
      Минусы библиотеки:
      - Довольно слабая декларативность при описании грамматики
      - Неудобная обработка ошибок, отсутствие качественной кастомизации в их обработке
      - По умолчанию ошибки, которые возникают при парсинге, не дают практически никакой информации о том, что именно не удалось распарсить 
      - Она на питоне...

### Как читать AST 

Практически у всех узлов AST есть отдельные типы. Они будут выводиться. Также, если тип проще, чем pllaceholder, то будет выведено также содержимое соответствующего объекта (поля структуры)

Пример того, как выглядит описание узла AST типа `Expression` (`2 + 2 * 7 && 1 || 1 >= 0`) в конcоли
```
IntegerLiteral  2

IntegerLiteral  2

IntegerLiteral  7

EvalMultOp [<__main__.IntegerLiteral object at 0x7fc6152b2df0>, '*', <__main__.IntegerLiteral object at 0x7fc615398670>]

EvalAddOp [<__main__.IntegerLiteral object at 0x7fc615392fd0>, '+', <__main__.EvalMultOp object at 0x7fc6153982e0>]

IntegerLiteral  1

EvalAndOp [<__main__.EvalAddOp object at 0x7fc615398c70>, '&&', <__main__.IntegerLiteral object at 0x7fc6152bd1f0>]

IntegerLiteral  1

IntegerLiteral  0

EvalComparisonOp [<__main__.IntegerLiteral object at 0x7fc6152b2910>, '>=', <__main__.IntegerLiteral object at 0x7fc6152bd790>]

EvalOrOp [<__main__.EvalAndOp object at 0x7fc6152b2fd0>, '||', <__main__.EvalComparisonOp object at 0x7fc615398100>]
```

`IntegerLiteral` -- специальный узел AST, который хранит целочисленные литералы.

`EvalMultOp` -- специальный узел AST, который хранит операнды, над которыми производится умножение, а также хранит типы операций (подразумевается, что тут хранятся и деления, и умножения)

`EvalAddOp`, `EvalOrOp` -- аналогично

`EvalComparisonOp` -- на самом деле, работает очень похожим образом на EvalAddOp и EvalMulOp, хранит операнды и типы сравнений, которые были использованы

Общая логика такова, что слева указан тип ноды AST, а справа её содержимое

### Время работы

Я запускал на тех же тестах, что Серёжа и Артём. Все результаты были ожидаемые, однако не работает единственный тест, который у Артёма 5-й, `python` не хватает стека рекурсии. Самое долгое время на оставшихся тестах -- это 4 секунды, на тесте, который является у Артёма 6-м. На всех остальных тестах всё отработало в пределах секунды.

#### Appendix

Изначально мной была предпринята попытка написать парсер на библиотеке `lexy` на `C++`.
Однако проблема заключалась в том, что там отсутствовала нормальная документация и примеры. Помимо этого по умолчанию он был очень плохо заточен под парсинг арифметических выражений. В итоге, спустя полтора дня страданий, было принято решение поменять выбор библиотеки и языка. Однако из плюсов хочется отметить обработку ошибок там. Она прекрасна.
